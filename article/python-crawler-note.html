<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><title>Python 爬蟲常用技巧 (持續更新) | Titangene Blog</title><meta name="description" content="利用 blog 紀錄學習歷程"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="HandheldFriendly" content="True"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="author" content="Titangene"><link rel="shortcut icon" href="/favicon.ico"><link rel="alternate" href="/atom.xml" title="Titangene Blog"><meta name="description" content="紀錄個人常用的 Python 爬蟲技巧，未來還會持續更新其他技巧。"><meta name="keywords" content="Python Requests"><meta property="og:type" content="article"><meta property="og:title" content="Python 爬蟲常用技巧 (持續更新)"><meta property="og:url" content="https://titangene.github.io/article/python-crawler-note.html"><meta property="og:site_name" content="Titangene Blog"><meta property="og:description" content="紀錄個人常用的 Python 爬蟲技巧，未來還會持續更新其他技巧。"><meta property="og:locale" content="zh-tw"><meta property="og:image" content="https://titangene.github.io/images/cover/python_crawler.png"><meta property="og:updated_time" content="2019-09-21T01:59:47.478Z"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="Python 爬蟲常用技巧 (持續更新)"><meta name="twitter:description" content="紀錄個人常用的 Python 爬蟲技巧，未來還會持續更新其他技巧。"><meta name="twitter:image" content="https://titangene.github.io/images/cover/python_crawler.png"><meta name="twitter:creator" content="@titangeneTW"><meta name="twitter:site" content="@titangene_blog"><meta property="fb:admins" content="100001106016019"><meta property="fb:app_id" content="2470546159839111"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta name="google-site-verification" content="AaJ39L7h-nWwJjXJMhAMtXSF6H6BUgGWXC80kYvLic8"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Inconsolata|Titillium+Web"><link href="https://fonts.googleapis.com/css?family=Source+Code+Pro&display=swap" rel="stylesheet"><link rel="stylesheet" href="//use.fontawesome.com/releases/v5.7.0/css/all.css" integrity="sha384-lZN37f5QGtY3VHgisS14W3ExzMWZxybE1SJSEsQp9S+oqd12jhcu+A56Ebc1zFSJ" crossorigin="anonymous"><link rel="stylesheet" href="/style.css"><script async src="https://www.googletagmanager.com/gtag/js?id=UA-129758206-1"></script><script>!function(a){function n(){dataLayer.push(arguments)}a.dataLayer=a.dataLayer||[],n("js",new Date),n("config","UA-129758206-1")}(window)</script><script>function setLoadingBarProgress(e){document.getElementById("loading-bar").style.width=e+"%"}</script></head></html><body><div id="loading-bar-wrapper"><div id="loading-bar"></div></div><script>setLoadingBarProgress(20)</script><header class="l_header"><div class="wrapper"><div class="nav-main container container--flex"><a class="logo flat-box" href="/">Titangene Blog</a><div class="menu"><ul class="h-list"><li><a class="flat-box nav-home" href="/">Home</a></li><li><a class="flat-box nav-archives" href="/archives">Archives</a></li></ul><div class="underline"></div></div><div class="m_search"><form name="searchform" class="form u-search-form"><input type="text" class="input u-search-input" placeholder="Search"> <i class="fas fa-search"></i></form></div><ul class="switcher h-list"><li class="s-search"><a class="fas fa-search" href="javascript:void(0)"></a></li><li class="s-menu"><a class="fas fa-bars" href="javascript:void(0)"></a></li></ul></div><div class="nav-sub container container--flex"><a class="logo flat-box" href="/">Titangene Blog</a><ul class="switcher h-list"><li class="s-comment"><a class="far fa-comment-alt" href="javascript:void(0)"></a></li><li class="s-top"><a class="fas fa-arrow-up" href="javascript:void(0)"></a></li><li class="s-toc"><a class="fas fa-list-ol" href="javascript:void(0)"></a></li></ul></div></div></header><aside class="menu-phone"><nav><a href="/" class="nav-home nav">Home </a><a href="/archives" class="nav-archives nav">Archives</a></nav></aside><script>setLoadingBarProgress(40)</script><div class="l_body"><div class="container clearfix"><div class="l_main"><article id="post-python-crawler-note" class="post white-box article-type-post" itemscope itemprop="blogPost"><section class="meta"><h2 class="title"><a href="/article/python-crawler-note.html">Python 爬蟲常用技巧 (持續更新)</a></h2><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar"></i> </span><span class="post-meta-item-text">發表於</span> <time title="建立時間：2019-02-28 17:33:51" itemprop="dateCreated datePublished" datetime="2019-02-28T17:33:51+08:00">2019-02-28 </time><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-calendar-check"></i> </span><span class="post-meta-item-text">更新於</span> <time title="修改時間：2019-09-21 09:59:47" itemprop="dateModified" datetime="2019-09-21T09:59:47+08:00">2019-09-21</time></span> <span class="comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fas fa-comment"></i> </span><a href="https://titangene.github.io/article/python-crawler-note.html#disqus_thread" class="article-comment-count" data-disqus-identifier="article/python-crawler-note.html" itemprop="discussionUrl"></a></span><div class="post-category"><span class="post-meta-item-icon"><i class="fa fa-folder"></i> </span><span class="post-meta-item-text">分類於</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a>, <a href="/categories/python/crawler/" itemprop="url" rel="index"><span itemprop="name">Crawler</span></a></span></div></section><section class="toc-wrapper"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#載入常用套件"><span class="toc-text">載入常用套件</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#解析-html"><span class="toc-text">解析 HTML</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#解析網址"><span class="toc-text">解析網址</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#將-parseresult-物件轉成網址字串"><span class="toc-text">將 ParseResult 物件轉成網址字串</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#解析網址-query"><span class="toc-text">解析網址 query</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#隨機生成-user-agent"><span class="toc-text">隨機生成 user-agent</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#fake-useragent-套件"><span class="toc-text">fake_useragent 套件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#user-agent-套件"><span class="toc-text">user_agent 套件</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#讀取表格資料"><span class="toc-text">讀取表格資料</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#讀取-解析-json"><span class="toc-text">讀取/解析 JSON</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#讀取-解析-xml"><span class="toc-text">讀取/解析 XML</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#讀取-xml-檔"><span class="toc-text">讀取 XML 檔</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#讀取-xml-字串"><span class="toc-text">讀取 XML 字串</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#迴圈取得子元素"><span class="toc-text">迴圈取得子元素</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#用-index-取得某元素"><span class="toc-text">用 index 取得某元素</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#搜尋指定元素"><span class="toc-text">搜尋指定元素</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#下載圖片"><span class="toc-text">下載圖片</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#下載大檔案"><span class="toc-text">下載大檔案</span></a></li></ol></section><section class="article typo"><div class="article-entry" itemprop="articleBody"><p>紀錄個人常用的 Python 爬蟲技巧，未來還會持續更新其他技巧。</p><a id="more"></a><h2 id="載入常用套件"><a class="header-anchor" href="#載入常用套件"></a>載入常用套件</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> shutil<br><span class="hljs-keyword">import</span> xml.etree.ElementTree <span class="hljs-keyword">as</span> ET<br><span class="hljs-keyword">from</span> urllib.parse <span class="hljs-keyword">import</span> urlparse, parse_qs, urlunparse<br><br><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup<br><span class="hljs-keyword">from</span> user_agent <span class="hljs-keyword">import</span> generate_user_agent<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br></code></pre></td></tr></table></figure><h2 id="解析-html"><a class="header-anchor" href="#解析-html"></a>解析 HTML</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup<br><br>response = requests.get(url)<br>soup = BeautifulSoup(response.text, <span class="hljs-string">'lxml'</span>)<br>html = soup.find(id=<span class="hljs-string">'some_id'</span>)<br></code></pre></td></tr></table></figure><h2 id="解析網址"><a class="header-anchor" href="#解析網址"></a>解析網址</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> urllib.parse <span class="hljs-keyword">import</span> urlparse, parse_qs, urlunparse<br><br>url = <span class="hljs-string">'http://xxx.com/api/data?id=123&amp;sub_code=06A1297'</span><br>link_parse = urlparse(url)<br>print(link_parse)<br></code></pre></td></tr></table></figure><p>輸出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">ParseResult(scheme=&apos;http&apos;, netloc=&apos;xxx.com&apos;, path=&apos;/api/data&apos;, params=&apos;&apos;, query=&apos;id=123&amp;sub_code=06A1297&apos;, fragment=&apos;&apos;)<br></code></pre></td></tr></table></figure><h3 id="將-parseresult-物件轉成網址字串"><a class="header-anchor" href="#將-parseresult-物件轉成網址字串"></a>將 <code>ParseResult</code> 物件轉成網址字串</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">url = urlunparse(link_parse)<br>print(url)<br></code></pre></td></tr></table></figure><p>輸出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">&apos;http://xxx.com/api/data?id=123&amp;sub_code=06A1297&apos;<br></code></pre></td></tr></table></figure><h3 id="解析網址-query"><a class="header-anchor" href="#解析網址-query"></a>解析網址 query</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">link_query = parse_qs(link_parse.query)<br>print(link_query)<br><br>id = link_query[<span class="hljs-string">'id'</span>][<span class="hljs-number">0</span>]<br>sub_code = link_query[<span class="hljs-string">'sub_code'</span>][<span class="hljs-number">0</span>]<br>print(id, sub_code)<br></code></pre></td></tr></table></figure><p>輸出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">&#123;&apos;id&apos;: [&apos;123&apos;], &apos;sub_code&apos;: [&apos;06A1297&apos;]&#125;<br>123 06A1297<br></code></pre></td></tr></table></figure><h2 id="隨機生成-user-agent"><a class="header-anchor" href="#隨機生成-user-agent"></a>隨機生成 user-agent</h2><h3 id="fake-useragent-套件"><a class="header-anchor" href="#fake-useragent-套件"></a>fake_useragent 套件</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">from</span> fake_useragent <span class="hljs-keyword">import</span> UserAgent<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">set_header_user_agent</span><span class="hljs-params">()</span>:</span><br>    user_agent = UserAgent()<br>    <span class="hljs-keyword">return</span> user_agent.random<br><br>user_agent = set_header_user_agent()<br>response = requests.get(url, headers=&#123; <span class="hljs-string">'user-agent'</span>: user_agent &#125;)<br></code></pre></td></tr></table></figure><h3 id="user-agent-套件"><a class="header-anchor" href="#user-agent-套件"></a>user_agent 套件</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">from</span> user_agent <span class="hljs-keyword">import</span> generate_user_agent<br><br>user_agent = generate_user_agent()<br>response = requests.get(url, headers=&#123; <span class="hljs-string">'user-agent'</span>: user_agent &#125;)<br></code></pre></td></tr></table></figure><h2 id="讀取表格資料"><a class="header-anchor" href="#讀取表格資料"></a>讀取表格資料</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br>response = requests.get(url)<br>soup = BeautifulSoup(response.text, <span class="hljs-string">'lxml'</span>)<br>html = soup.find(id=<span class="hljs-string">'table_id'</span>)<br>df = pd.read_html(str(html), header=<span class="hljs-number">0</span>)[<span class="hljs-number">0</span>]<br></code></pre></td></tr></table></figure><h2 id="讀取-解析-json"><a class="header-anchor" href="#讀取-解析-json"></a>讀取/解析 JSON</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> json<br><br><span class="hljs-comment"># 讀取</span><br><span class="hljs-keyword">with</span> open(<span class="hljs-string">'data.json'</span>, encoding=<span class="hljs-string">'utf-8'</span>) <span class="hljs-keyword">as</span> file:<br>    datas = json.load(file)<br><br><span class="hljs-comment"># 解析</span><br><span class="hljs-keyword">with</span> open(<span class="hljs-string">'data.json'</span>, <span class="hljs-string">'w'</span>, encoding=<span class="hljs-string">'utf-8'</span>) <span class="hljs-keyword">as</span> file:<br>    json.dump(datas, file, ensure_ascii=<span class="hljs-keyword">False</span>)<br></code></pre></td></tr></table></figure><h2 id="讀取-解析-xml"><a class="header-anchor" href="#讀取-解析-xml"></a>讀取/解析 XML</h2><h3 id="讀取-xml-檔"><a class="header-anchor" href="#讀取-xml-檔"></a>讀取 XML 檔</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> xml.etree.ElementTree <span class="hljs-keyword">as</span> ET<br><br>tree = ET.parse(<span class="hljs-string">'data.xml'</span>)<br>root = tree.getroot()<br></code></pre></td></tr></table></figure><h3 id="讀取-xml-字串"><a class="header-anchor" href="#讀取-xml-字串"></a>讀取 XML 字串</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> xml.etree.ElementTree <span class="hljs-keyword">as</span> ET<br><br>root = ET.fromstring(some_xml_strings)<br></code></pre></td></tr></table></figure><p>以下面的 XML 為範例：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-meta">&lt;?xml version="1.0"?&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">bookstore</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">book</span> <span class="hljs-attr">ISBN</span>=<span class="hljs-string">"10-000000-001"</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">title</span>&gt;</span>Book 1<span class="hljs-tag">&lt;/<span class="hljs-name">title</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">price</span>&gt;</span>300<span class="hljs-tag">&lt;/<span class="hljs-name">price</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">comments</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">userComment</span> <span class="hljs-attr">rating</span>=<span class="hljs-string">"4"</span>&gt;</span>xxx...<span class="hljs-tag">&lt;/<span class="hljs-name">userComment</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">userComment</span> <span class="hljs-attr">rating</span>=<span class="hljs-string">"2"</span>&gt;</span>yyy...<span class="hljs-tag">&lt;/<span class="hljs-name">userComment</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">comments</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">book</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">book</span> <span class="hljs-attr">ISBN</span>=<span class="hljs-string">"10-000000-999"</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">title</span>&gt;</span>Book 2<span class="hljs-tag">&lt;/<span class="hljs-name">title</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">price</span>&gt;</span>500<span class="hljs-tag">&lt;/<span class="hljs-name">price</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">comments</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">userComment</span> <span class="hljs-attr">rating</span>=<span class="hljs-string">"3"</span>&gt;</span>zzz...<span class="hljs-tag">&lt;/<span class="hljs-name">userComment</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">comments</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">book</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">bookstore</span>&gt;</span><br></code></pre></td></tr></table></figure><h3 id="迴圈取得子元素"><a class="header-anchor" href="#迴圈取得子元素"></a>迴圈取得子元素</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> child <span class="hljs-keyword">in</span> root:<br>    print(child.tag, child.attrib)<br></code></pre></td></tr></table></figure><p>輸出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">book &#123;&apos;ISBN&apos;: &apos;10-000000-001&apos;&#125;<br>book &#123;&apos;ISBN&apos;: &apos;10-000000-999&apos;&#125;<br></code></pre></td></tr></table></figure><h3 id="用-index-取得某元素"><a class="header-anchor" href="#用-index-取得某元素"></a>用 index 取得某元素</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">root[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>].tag<br>root[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>].text<br>root[<span class="hljs-number">0</span>].attrib<br></code></pre></td></tr></table></figure><p>輸出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined">&apos;price&apos;<br>&apos;300&apos;<br>&#123;&apos;ISBN&apos;: &apos;10-000000-001&apos;&#125;<br></code></pre></td></tr></table></figure><h3 id="搜尋指定元素"><a class="header-anchor" href="#搜尋指定元素"></a>搜尋指定元素</h3><p>使用 <code>root.iter()</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> comment <span class="hljs-keyword">in</span> root.iter(<span class="hljs-string">'userComment'</span>):<br>    print(comment.attrib)<br>    print(<span class="hljs-string">'comment: &#123;&#125;'</span>.format(comment.text))<br></code></pre></td></tr></table></figure><p>輸出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs undefined">&#123;&apos;rating&apos;: &apos;4&apos;&#125;<br>comment: xxx...<br>&#123;&apos;rating&apos;: &apos;2&apos;&#125;<br>comment: yyy...<br>&#123;&apos;rating&apos;: &apos;3&apos;&#125;<br>comment: zzz...<br></code></pre></td></tr></table></figure><p>使用 <code>root.findall()</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> book <span class="hljs-keyword">in</span> root.findall(<span class="hljs-string">'book'</span>):<br>    ISBN = book.get(<span class="hljs-string">'ISBN'</span>)<br>    title = book.find(<span class="hljs-string">'title'</span>).text<br>    print(ISBN, title)<br></code></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">10-000000-001 Book 1<br>10-000000-999 Book 2<br></code></pre></td></tr></table></figure><h2 id="下載圖片"><a class="header-anchor" href="#下載圖片"></a>下載圖片</h2><p><code>response.raw</code> 是 file-like 物件，預設不會解壓縮 response (使用 gzip 或 deflate，參考至 <a href="https://github.com/kennethreitz/requests/blob/master/requests/utils.py#L808" target="_blank" rel="noopener">Requests 原始碼</a>)，可以透過在 <code>requests.get()</code> 方法中，新增參數 <code>stream=True</code> 來強制解壓縮，並且可以避免立即將大的 response 內容讀入記憶體內，接著使用 <code>shutil.copyfileobj()</code> 讓 Python 將 串流資料轉成檔案物件。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">import</span> shutil<br><br>url = <span class="hljs-string">"http://www.xxx.com/xxx.png"</span><br>response = requests.get(url, stream=<span class="hljs-keyword">True</span>)<br>file_name = url.split(<span class="hljs-string">'/'</span>)[<span class="hljs-number">-1</span>]<br><span class="hljs-keyword">with</span> open(file_name, <span class="hljs-string">'wb'</span>) <span class="hljs-keyword">as</span> file:<br>    shutil.copyfileobj(response.raw, file)<br></code></pre></td></tr></table></figure><p>如果要下載檔案大的圖片，可參考下個段落「<a href="#%E4%B8%8B%E8%BC%89%E5%A4%A7%E6%AA%94%E6%A1%88">下載大檔案</a>」。</p><div class="info"><p><code>shutil.copyfileobj(fsrc, fdst[, length])</code>：將 file-like 物件 <code>fsrc</code> 的內容複製到 file-like 物件 <code>fdst</code>。<code>length</code> 參數 (int) 是 buffer 的大小。如果 <code>length</code> 為負數則代表是複製資料，而不以 chunk 的形式循環原始資料；預設是資料以 chunk 的形式讀取，以避免不受控制的記憶體消耗。請注意，如果 <code>fsrc</code> 物件的當前檔案位置不為 0，則只複製從當前檔案位置到檔案末端的內容。</p><blockquote><p>參考至 <a href="https://docs.python.org/3/library/shutil.html#shutil.copyfileobj" target="_blank" rel="noopener">shutil - High-level file operations - Python 3.7.3 documentation</a> 官方文件。</p></blockquote></div><blockquote><p>參考來源：<a href="https://stackoverflow.com/questions/13137817/how-to-download-image-using-requests" target="_blank" rel="noopener">python - How to download image using requests - Stack Overflow</a></p></blockquote><h2 id="下載大檔案"><a class="header-anchor" href="#下載大檔案"></a>下載大檔案</h2><p>以迭代的方式取得，預設會以每 128 byte 為一個 chunk 來讀取資料 (參考至 <a href="https://github.com/kennethreitz/requests/blob/master/requests/models.py#L688" target="_blank" rel="noopener">Requests 原始碼</a>)：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<br><br>response = requests.get(url, stream=<span class="hljs-keyword">True</span>)<br>file_name = url.split(<span class="hljs-string">'/'</span>)[<span class="hljs-number">-1</span>]<br><span class="hljs-keyword">with</span> open(file_name, <span class="hljs-string">'wb'</span>) <span class="hljs-keyword">as</span> file:<br>    <span class="hljs-keyword">for</span> chunk <span class="hljs-keyword">in</span> response:<br>        file.write(chunk)<br></code></pre></td></tr></table></figure><p>若要自訂 chunk 大小，可使用 <a href="https://github.com/kennethreitz/requests/blob/master/requests/models.py#L729" target="_blank" rel="noopener"><code>Response.iter_content()</code></a> 方法自訂：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<br><br>file_name = url.split(<span class="hljs-string">'/'</span>)[<span class="hljs-number">-1</span>]<br><span class="hljs-keyword">with</span> requests.get(url, stream=<span class="hljs-keyword">True</span>) <span class="hljs-keyword">as</span> response:<br>    response.raise_for_status()<br>    <span class="hljs-keyword">with</span> open(file_name, <span class="hljs-string">'wb'</span>) <span class="hljs-keyword">as</span> file:<br>        <span class="hljs-keyword">for</span> chunk <span class="hljs-keyword">in</span> response.iter_content(chunk_size=<span class="hljs-number">8192</span>):<br>            <span class="hljs-keyword">if</span> chunk: <span class="hljs-comment"># filter out keep-alive new chunks</span><br>                file.write(chunk)<br>                <span class="hljs-comment"># file.flush()</span><br></code></pre></td></tr></table></figure><blockquote><p>參考來源：<a href="https://stackoverflow.com/questions/16694907/download-large-file-in-python-with-requests" target="_blank" rel="noopener">Download large file in python with requests - Stack Overflow</a></p></blockquote><p>若想要以一次一行的方式迭代 response 資料，可使用 <a href="https://github.com/kennethreitz/requests/blob/master/requests/models.py#L784" target="_blank" rel="noopener"><code>Response.iter_lines()</code></a> 方法，此方法預設一個 chunk 的大小為 512 byte，若要設定分隔符號，可加上 <code>delimiter</code> 參數：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> requests<br><br>r = requests.get(url, stream=<span class="hljs-keyword">True</span>)<br><span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> r.iter_lines():<br>    <span class="hljs-comment"># filter out keep-alive new lines</span><br>    <span class="hljs-keyword">if</span> line:<br>        print(json.loads(line))<br></code></pre></td></tr></table></figure><blockquote><p>參考來源：<a href="https://www.cnblogs.com/linxiyue/p/3980003.html" target="_blank" rel="noopener">Python Requests 庫：HTTP for Humans - 再見紫羅蘭 - 博客園</a></p></blockquote></div><div class="article-tags tags"><a href="/tags/python-requests/" title="Python Requests">Python Requests</a></div></section><div class="article-share-links"><span>分享：</span> <a class="fab fa-facebook-f" title="Facebook" target="_blank" href="javascript:window.open('https://www.facebook.com/sharer.php?u=https%3A%2F%2Ftitangene.github.io%2Farticle%2Fpython-crawler-note.html', 'Share on Facebook','width=600, height=600')"></a> <a class="fab fa-twitter" title="Twitter" target="_blank" href="javascript:window.open('https://twitter.com/share?url=https%3A%2F%2Ftitangene.github.io%2Farticle%2Fpython-crawler-note.html&amp;text=Python 爬蟲常用技巧 (持續更新)&amp;hashtags=PythonRequests&amp;via=titangene_blog', 'Share on Twitter','width=600, height=260')"></a> <a class="fab fa-linkedin-in" title="Linkedin" target="_blank" href="javascript:window.open('https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Ftitangene.github.io%2Farticle%2Fpython-crawler-note.html&amp;title=Python 爬蟲常用技巧 (持續更新)', 'Share on Linkedin','width=600, height=600')"></a> <a class="fab fa-facebook-messenger" title="Facebook Messenger" target="_blank" href="javascript:window.open('http://www.facebook.com/dialog/send?app_id=2470546159839111&amp;link=https%3A%2F%2Ftitangene.github.io%2Farticle%2Fpython-crawler-note.html&amp;display=popup&amp;redirect_uri=https%3A%2F%2Fwww.facebook.com%2Fdialog%2Freturn%2Fclose%23_%3D_', 'Send in Messenger','width=600, height=600')"></a> <a class="fab fa-telegram-plane" href="https://telegram.me/share/url?url=https%3A%2F%2Ftitangene.github.io%2Farticle%2Fpython-crawler-note.html&text=Python 爬蟲常用技巧 (持續更新)" target="_blank"></a></div><nav id="article-nav"><a href="/article/gcp-vm-nignx-web-server.html" id="article-nav-prev" class="article-nav-link-wrap" title="在 GCP 上建立 VM 架設 NIGNX Web server" rel="prev"><strong class="article-nav-caption">Prev</strong><p class="article-nav-title">在 GCP 上建立 VM 架設 NIGNX Web server</p><i class="fas fa-angle-left"></i> </a><a href="/article/hexo-copy-code-snippet-to-clipboard.html" id="article-nav-next" class="article-nav-link-wrap" title="在 Hexo 主題內新增程式碼片段複製功能" rel="next"><strong class="article-nav-caption">Next</strong><p class="article-nav-title">在 Hexo 主題內新增程式碼片段複製功能</p><i class="fas fa-angle-right"></i></a></nav><section id="list_related_posts"><h2>相關文章</h2><ul class="related-posts"><li class="related-posts-item"><a class="related-posts-link" href="/article/set-up-windows-task-scheduler-to-periodically-execute-python-crawler.html">設定 Windows 工作排程定期執行 Python 爬蟲程式</a><div class="related-posts-item-abstract">如何將 Python 爬蟲程式定期執行？使用 Windows 的使用者可以選擇「工作排程器」來解決。最近有些資料想透過爬蟲來擷取，而且希望可以定期 (例如：每 10 分鐘一次) 自動執行爬蟲程式，因此就有了這篇筆記。下面</div></li></ul></section><section class="comments" id="comments"><h2>討論區</h2><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div></section></article><script>window.subData={title:"Python 爬蟲常用技巧 (持續更新)",tools:!0}</script></div><aside class="l_side"><section class="m_widget about"><div class="avatar-section"><style>.avatar-cover{background:url(/images/avatar_cover.jpg) 0 10%/cover no-repeat}</style><div class="avatar-cover"></div><img class="avatar" src="/images/avatar.jpg"></div><div class="header">Titangene</div><div class="content"><div class="desc">利用 blog 紀錄學習歷程</div></div><div class="content"><meta itemprop="url" content="https://titangene.github.io"><div class="social-wrapper"><a itemprop="sameAs" href="https://github.com/titangene" class="social github" target="_blank" rel="external"><span class="fab fa-github-alt"></span> </a><a itemprop="sameAs" href="https://www.facebook.com/titangene.tw" class="social facebook" target="_blank" rel="external"><span class="fab fa-facebook-square"></span> </a><a itemprop="sameAs" href="https://www.instagram.com/titangene/" class="social instagram" target="_blank" rel="external"><span class="fab fa-instagram"></span> </a><a itemprop="sameAs" href="https://www.flickr.com/photos/titangene" class="social flickr" target="_blank" rel="external"><span class="fab fa-flickr"></span> </a><a itemprop="sameAs" href="/atom.xml" class="social rss" target="_blank" rel="external"><span class="fas fa-rss"></span></a></div></div></section><section class="m_widget facebook_page"><div class="fb-page" data-href="https://www.facebook.com/titangene.blog/" data-width="250" data-small-header="false" data-adapt-container-width="false" data-hide-cover="false" data-show-facepile="true"><blockquote cite="https://www.facebook.com/titangene.blog/" class="fb-xfbml-parse-ignore"><p><a href="https://www.facebook.com/titangene.blog/" class="social facebook" target="_blank"><span class="fab fa-facebook-square"></span></a></p><p><a href="https://www.facebook.com/titangene.blog/">Titangene Blog</a></p><p>Loading...</p></blockquote></div></section><section class="m_widget recent"><div class="header">Recents</div><div class="content"><ul class="entry"><li><a itemprop="url" class="flat-box" href="/article/css-attribute-value.html"><time>2019-09-22</time><div class="name">重新認識 CSS - CSS 屬性值</div></a></li><li><a itemprop="url" class="flat-box" href="/article/css-selector-pseudo-element.html"><time>2019-09-21</time><div class="name">重新認識 CSS - Pseudo-element (偽元素)</div></a></li><li><a itemprop="url" class="flat-box" href="/article/css-selector-pseudo-class-2.html"><time>2019-09-20</time><div class="name">重新認識 CSS - Pseudo-class (偽類) (2)</div></a></li><li><a itemprop="url" class="flat-box" href="/article/css-selector-pseudo-class-1.html"><time>2019-09-19</time><div class="name">重新認識 CSS - Pseudo-class (偽類) (1)</div></a></li><li><a itemprop="url" class="flat-box" href="/article/css-attribute-selector.html"><time>2019-09-18</time><div class="name">重新認識 CSS - Attribute selector (屬性選擇器)</div></a></li></ul></div></section></aside><script>setLoadingBarProgress(60)</script></div></div><footer id="footer" class="clearfix"><div class="social-wrapper"><a href="https://github.com/titangene" class="social github" target="_blank" rel="external"><span class="fab fa-github-alt"></span> </a><a href="https://www.facebook.com/titangene.tw" class="social facebook" target="_blank" rel="external"><span class="fab fa-facebook-square"></span> </a><a href="https://www.instagram.com/titangene/" class="social instagram" target="_blank" rel="external"><span class="fab fa-instagram"></span> </a><a href="https://www.flickr.com/photos/titangene" class="social flickr" target="_blank" rel="external"><span class="fab fa-flickr"></span> </a><a href="/atom.xml" class="social rss" target="_blank" rel="external"><span class="fas fa-rss"></span></a></div><div>© 2018 - 2019 <span itemprop="copyrightHolder">Titangene</span></div><div>Powered by <a href="https://hexo.io/" class="codename" rel="external">Hexo</a> - Theme <a href="https://github.com/stkevintan/hexo-theme-material-flow" class="codename" rel="external">MaterialFlow</a></div><div><a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png"></a></div></footer><script>setLoadingBarProgress(80)</script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.1.4/jquery.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.24.0/moment-with-locales.min.js"></script><script>moment.locale("zh-tw")</script><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script src="/js/jquery.fitvids.js"></script><script>var SEARCH_SERVICE="hexo",ROOT="/";ROOT.endsWith("/")||(ROOT+="/")</script><script src="/js/search.js"></script><script src="/js/app.js"></script><script src="/js/clipboard-use.js"></script><script>var disqus_shortname="titangene-blog",disqus_config=function(){this.page.url="https://titangene.github.io/article/python-crawler-note.html",this.page.identifier="article/python-crawler-note.html",this.page.title="Python 爬蟲常用技巧 (持續更新)"};!function(){var t=document.createElement("script");t.async=!0,t.src="//"+disqus_shortname+".disqus.com/embed.js",t.setAttribute("data-timestamp",""+new Date),(document.head||document.body).appendChild(t)}()</script><script id="dsq-count-scr" src="https://titangene-blog.disqus.com/count.js" async></script><div id="fb-root"></div><script>window.fbAsyncInit=function(){FB.init({appId:"2470546159839111",autoLogAppEvents:!0,xfbml:!0,version:"v2.11"}),FB.AppEvents.logPageView()},function(e,n,t){var o,s=e.getElementsByTagName(n)[0];e.getElementById(t)||((o=e.createElement(n)).id=t,o.src="//connect.facebook.net/zh_TW/sdk.js",s.parentNode.insertBefore(o,s))}(document,"script","facebook-jssdk")</script><script>setLoadingBarProgress(100)</script></body>